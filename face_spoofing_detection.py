# -*- coding: utf-8 -*-
"""deep_learning_project1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TqV7VR3mNd1opabkScExC7TBV2lya_vn

## **Yüz Sahteciliği Tespiti İçin Derin Öğrenme Yöntemleri**:
"""

import tensorflow as tf
import numpy as np
import os
import cv2
import pandas as pd
import matplotlib.pyplot as plt
import warnings
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D, BatchNormalization
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.optimizers import Adam, Nadam, Adadelta, SGD
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.applications import VGG16, MobileNetV2, EfficientNetB0
from tensorflow.keras.regularizers import l2
from tensorflow.keras.preprocessing.image import ImageDataGenerator

"""# Veri Seti Klasör Yolları;"""

real_path = "/content/drive/MyDrive/real"
fake_path = "/content/drive/MyDrive/fake"

"""# Görüntülerin Yüklenmesi ve Etiketlenmesi;"""

from google.colab import drive
drive.mount('/content/drive')

def load_images_and_labels(folder, label):
    images = []
    labels = []
    for filename in os.listdir(folder):
        filepath = os.path.join(folder, filename)
        img = cv2.imread(filepath)
        if img is not None:
            img = cv2.resize(img, (64, 64))  # Çok basit model için küçük boyutta
            images.append(img)
            labels.append(label)
    return np.array(images), np.array(labels)

real_images, real_labels = load_images_and_labels(real_path, 1)
fake_images, fake_labels = load_images_and_labels(fake_path, 0)

"""# Veri Seti Görüntü Sayısı"""

print(f"Real görüntü sayısı: {len(real_images)}")
print(f"Fake görüntü sayısı: {len(fake_images)}")

"""# Verilerin Birleştirilip, Eğitim ve Test Olarak Ayrılması"""

X = np.concatenate((real_images, fake_images), axis=0)
y = np.concatenate((real_labels, fake_labels), axis=0)
X = X / 255.0  # Normalizasyon
y = np.array(y)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f"Eğitim veri seti boyutu: {X_train.shape}")
print(f"Test veri seti boyutu: {X_test.shape}")

"""# Basit Bir CNN Modeli"""

def create_simple_cnn():
    model = Sequential([
        Conv2D(8, (3, 3), activation='elu', input_shape=(64, 64, 3)),
        MaxPooling2D((2, 2)),
        Flatten(),
        Dense(8, activation='elu'),
        Dense(1, activation='sigmoid')  # İkili sınıflandırma için sigmoid
    ])
    model.compile(optimizer=Adadelta(learning_rate=0.01),
                  loss='binary_crossentropy',
                  metrics=['accuracy'])
    return model

# Modeli oluştur ve eğit
model = create_simple_cnn()
history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=64)

"""-- Model1 Accuracy: % 59"""

plt.figure(figsize=(12, 4))
# Eğitim ve doğrulama kaybı
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Eğitim Kaybı')
plt.plot(history.history['val_loss'], label='Doğrulama Kaybı')
plt.legend()
plt.title('Model Kaybı')
plt.xlabel('Epok')
plt.ylabel('Kaybı')

# Eğitim ve doğrulama doğruluğu
plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], label='Eğitim Doğruluğu')
plt.plot(history.history['val_accuracy'], label='Doğrulama Doğruluğu')
plt.legend()
plt.title('Model Doğruluğu')
plt.xlabel('Epok')
plt.ylabel('Doğruluk')

plt.show()

"""# Aktivasyon Fonksiyonu Değiştirilmiş Hali"""

def model_with_activation_change():
    model = Sequential([
        Conv2D(8, (3, 3), activation='relu', input_shape=(64, 64, 3)),
        MaxPooling2D((2, 2)),
        Flatten(),
        Dense(16, activation='relu'),
        Dense(1, activation='sigmoid')
    ])
    model.compile(optimizer=Adam(learning_rate=0.001),
                  loss='binary_crossentropy',
                  metrics=['accuracy'])
    return model

model1 = model_with_activation_change()
history1 = model1.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=64)

"""-- Model2 Accuracy: %85"""

plt.figure(figsize=(12, 4))
# Eğitim ve doğrulama kaybı
plt.subplot(1, 2, 1)
plt.plot(history1.history['loss'], label='Eğitim Kaybı')
plt.plot(history1.history['val_loss'], label='Doğrulama Kaybı')
plt.legend()
plt.title('Model Kaybı')
plt.xlabel('Epok')
plt.ylabel('Kaybı')

# Eğitim ve doğrulama doğruluğu
plt.subplot(1, 2, 2)
plt.plot(history1.history['accuracy'], label='Eğitim Doğruluğu')
plt.plot(history1.history['val_accuracy'], label='Doğrulama Doğruluğu')
plt.legend()
plt.title('Model Doğruluğu')
plt.xlabel('Epok')
plt.ylabel('Doğruluk')

plt.show()

"""# Dropout Ekleyelim"""

def model_with_dropout():
    model = Sequential([
        Conv2D(16, (3, 3), activation='relu', input_shape=(64, 64, 3)),
        MaxPooling2D((2, 2)),
        Dropout(0.25),
        Conv2D(32, (3, 3), activation='relu'),
        MaxPooling2D((2, 2)),
        Flatten(),
        Dense(32, activation='relu'),
        Dropout(0.5),
        Dense(1, activation='sigmoid')
    ])
    model.compile(optimizer=Adam(learning_rate=0.001),
                  loss='binary_crossentropy',
                  metrics=['accuracy'])
    return model

model2 = model_with_dropout()
history2 = model2.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=15, batch_size=32)

"""-- Model3 Accuracy: % 64


"""

plt.figure(figsize=(12, 4))
# Eğitim ve doğrulama kaybı
plt.subplot(1, 2, 1)
plt.plot(history2.history['loss'], label='Eğitim Kaybı')
plt.plot(history2.history['val_loss'], label='Doğrulama Kaybı')
plt.legend()
plt.title('Model Kaybı')
plt.xlabel('Epok')
plt.ylabel('Kaybı')

# Eğitim ve doğrulama doğruluğu
plt.subplot(1, 2, 2)
plt.plot(history2.history['accuracy'], label='Eğitim Doğruluğu')
plt.plot(history2.history['val_accuracy'], label='Doğrulama Doğruluğu')
plt.legend()
plt.title('Model Doğruluğu')
plt.xlabel('Epok')
plt.ylabel('Doğruluk')

plt.show()

"""# Regularizyon Yapalım"""

def model_with_l2_regularization():
    model = Sequential([
        Conv2D(16, (3, 3), activation='relu', kernel_regularizer=l2(0.01), input_shape=(64, 64, 3)),
        MaxPooling2D((2, 2)),
        Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(0.01)),
        MaxPooling2D((2, 2)),
        Flatten(),
        Dense(64, activation='relu', kernel_regularizer=l2(0.01)),
        Dense(1, activation='sigmoid')
    ])
    model.compile(optimizer=Adam(learning_rate=0.001),
                  loss='binary_crossentropy',
                  metrics=['accuracy'])
    return model

model3 = model_with_l2_regularization()
history3 = model3.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=15, batch_size=32)

"""-- Model4 Accuracy: %60"""

plt.figure(figsize=(12, 4))
# Eğitim ve doğrulama kaybı
plt.subplot(1, 2, 1)
plt.plot(history3.history['loss'], label='Eğitim Kaybı')
plt.plot(history3.history['val_loss'], label='Doğrulama Kaybı')
plt.legend()
plt.title('Model Kaybı')
plt.xlabel('Epok')
plt.ylabel('Kaybı')

# Eğitim ve doğrulama doğruluğu
plt.subplot(1, 2, 2)
plt.plot(history3.history['accuracy'], label='Eğitim Doğruluğu')
plt.plot(history3.history['val_accuracy'], label='Doğrulama Doğruluğu')
plt.legend()
plt.title('Model Doğruluğu')
plt.xlabel('Epok')
plt.ylabel('Doğruluk')

plt.show()

"""# Verileri Arttıralım"""

datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True
)
datagen.fit(X_train)

# Model tanımı
def improved_model():
    model = Sequential([
        Conv2D(32, (3, 3), activation='elu', kernel_regularizer=l2(0.001), input_shape=(64, 64, 3)),
        MaxPooling2D((2, 2)),
        Dropout(0.2),  # İlk dropout katmanı
        Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.001)),
        MaxPooling2D((2, 2)),
        Dropout(0.3),  # İkinci dropout katmanı
        Flatten(),
        Dense(128, activation='relu', kernel_regularizer=l2(0.001)),
        Dropout(0.4),  # Son dropout katmanı
        Dense(1, activation='sigmoid')
    ])
    model.compile(optimizer=Adam(learning_rate=0.0001),
                  loss='binary_crossentropy',
                  metrics=['accuracy'])
    return model

# Model oluştur
model4 = improved_model()

# Early stopping
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# Eğitim
history4 = model.fit(
    datagen.flow(X_train, y_train, batch_size=16),  # Data augmentation ile eğitim
    validation_data=(X_test, y_test),
    epochs=25,  # Daha fazla epoch
    callbacks=[early_stopping]
)

"""--Model5 Accuracy:%51"""

plt.figure(figsize=(12, 4))
# Eğitim ve doğrulama kaybı
plt.subplot(1, 2, 1)
plt.plot(history4.history['loss'], label='Eğitim Kaybı')
plt.plot(history4.history['val_loss'], label='Doğrulama Kaybı')
plt.legend()
plt.title('Model Kaybı')
plt.xlabel('Epok')
plt.ylabel('Kaybı')

# Eğitim ve doğrulama doğruluğu
plt.subplot(1, 2, 2)
plt.plot(history4.history['accuracy'], label='Eğitim Doğruluğu')
plt.plot(history4.history['val_accuracy'], label='Doğrulama Doğruluğu')
plt.legend()
plt.title('Model Doğruluğu')
plt.xlabel('Epok')
plt.ylabel('Doğruluk')

plt.show()

"""# Küçük Değişiklikler"""

def model_with_small_tweaks():
    model = Sequential([
        Conv2D(32, (3, 3), activation='elu', input_shape=(64, 64, 3)),
        MaxPooling2D((2, 2)),
        Conv2D(64, (3, 3), activation='relu'),
        MaxPooling2D((2, 2)),
        Flatten(),
        Dropout(0.2),
        Dense(128, activation='relu'),
        Dense(1, activation='sigmoid')
    ])
    model.compile(optimizer=Adam(learning_rate=0.0005),  # Öğrenme oranı artırıldı
                  loss='binary_crossentropy',
                  metrics=['accuracy'])
    return model

# Model oluştur
model5 = model_with_small_tweaks()

# Early stopping
early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

# Modeli eğit
history5 = model.fit(
    X_train, y_train,
    validation_data=(X_test, y_test),
    epochs=25,
    batch_size=8,
    callbacks=[early_stopping]
)

"""--Model6 Accuracy: %62"""

plt.figure(figsize=(12, 4))
# Eğitim ve doğrulama kaybı
plt.subplot(1, 2, 1)
plt.plot(history5.history['loss'], label='Eğitim Kaybı')
plt.plot(history5.history['val_loss'], label='Doğrulama Kaybı')
plt.legend()
plt.title('Model Kaybı')
plt.xlabel('Epok')
plt.ylabel('Kaybı')

# Eğitim ve doğrulama doğruluğu
plt.subplot(1, 2, 2)
plt.plot(history5.history['accuracy'], label='Eğitim Doğruluğu')
plt.plot(history5.history['val_accuracy'], label='Doğrulama Doğruluğu')
plt.legend()
plt.title('Model Doğruluğu')
plt.xlabel('Epok')
plt.ylabel('Doğruluk')

plt.show()

"""# PRETRAINING MODEL -VGG16"""

def pretrained_vgg16():
    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(64, 64, 3))
    for layer in base_model.layers:
        layer.trainable = False  # Önceden eğitilmiş katmanları dondur
    model = Sequential([
        base_model,
        GlobalAveragePooling2D(),
        Dense(64, activation='relu'),
        Dense(1, activation='sigmoid')
    ])
    model.compile(optimizer=Adam(learning_rate=0.001),
                  loss='binary_crossentropy',
                  metrics=['accuracy'])
    return model

model6 = pretrained_vgg16()
history6 = model6.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)

"""--Model7 Accuracy: %81"""

plt.figure(figsize=(12, 4))
# Eğitim ve doğrulama kaybı
plt.subplot(1, 2, 1)
plt.plot(history6.history['loss'], label='Eğitim Kaybı')
plt.plot(history6.history['val_loss'], label='Doğrulama Kaybı')
plt.legend()
plt.title('Model Kaybı')
plt.xlabel('Epok')
plt.ylabel('Kaybı')

# Eğitim ve doğrulama doğruluğu
plt.subplot(1, 2, 2)
plt.plot(history6.history['accuracy'], label='Eğitim Doğruluğu')
plt.plot(history6.history['val_accuracy'], label='Doğrulama Doğruluğu')
plt.legend()
plt.title('Model Doğruluğu')
plt.xlabel('Epok')
plt.ylabel('Doğruluk')

plt.show()

"""# Batch Size'ı Düşürelim"""

def model_with_batch_size():
    model = Sequential([
        Conv2D(32, (3, 3), activation='elu', input_shape=(64, 64, 3)),
        MaxPooling2D((2, 2)),
        Conv2D(64, (3, 3), activation='relu'),
        MaxPooling2D((2, 2)),
        Flatten(),
        Dense(128, activation='relu'),
        Dense(1, activation='sigmoid')
    ])
    model.compile(optimizer=Adam(learning_rate=0.0001),
                  loss='binary_crossentropy',
                  metrics=['accuracy'])
    return model

model7 = model_with_batch_size()
history7 = model7.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=25, batch_size=4)

"""--Model8 Accuracy: %96"""

plt.figure(figsize=(12, 4))
# Eğitim ve doğrulama kaybı
plt.subplot(1, 2, 1)
plt.plot(history7.history['loss'], label='Eğitim Kaybı')
plt.plot(history7.history['val_loss'], label='Doğrulama Kaybı')
plt.legend()
plt.title('Model Kaybı')
plt.xlabel('Epok')
plt.ylabel('Kaybı')

# Eğitim ve doğrulama doğruluğu
plt.subplot(1, 2, 2)
plt.plot(history7.history['accuracy'], label='Eğitim Doğruluğu')
plt.plot(history7.history['val_accuracy'], label='Doğrulama Doğruluğu')
plt.legend()
plt.title('Model Doğruluğu')
plt.xlabel('Epok')
plt.ylabel('Doğruluk')

plt.show()

"""# PRETRAINING MODEL - MOBILENET"""

def pretrained_mobilenet():
    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(64, 64, 3))
    for layer in base_model.layers:
        layer.trainable = False  # Önceden eğitilmiş katmanları dondur
    model = Sequential([
        base_model,
        GlobalAveragePooling2D(),
        Dense(64, activation='relu'),
        Dense(1, activation='sigmoid')
    ])
    model.compile(optimizer=Adam(learning_rate=0.0001),
                  loss='binary_crossentropy',
                  metrics=['accuracy'])
    return model

early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

model8 = pretrained_mobilenet()
history8 = model8.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=25, batch_size=16, callbacks=[early_stopping])

"""--Model9 Accuracy: %98"""

plt.figure(figsize=(12, 4))
# Eğitim ve doğrulama kaybı
plt.subplot(1, 2, 1)
plt.plot(history8.history['loss'], label='Eğitim Kaybı')
plt.plot(history8.history['val_loss'], label='Doğrulama Kaybı')
plt.legend()
plt.title('Model Kaybı')
plt.xlabel('Epok')
plt.ylabel('Kaybı')

# Eğitim ve doğrulama doğruluğu
plt.subplot(1, 2, 2)
plt.plot(history8.history['accuracy'], label='Eğitim Doğruluğu')
plt.plot(history8.history['val_accuracy'], label='Doğrulama Doğruluğu')
plt.legend()
plt.title('Model Doğruluğu')
plt.xlabel('Epok')
plt.ylabel('Doğruluk')

plt.show()

"""# **Modellerin accuracy değişiklikleri:**
## %59 -> %85 -> %64 -> %60 -> %51 -> %62 -> %81 -> %96 -> %98
"""